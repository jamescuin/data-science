{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bd399cd",
   "metadata": {},
   "source": [
    "# Text Summarisation Using Transformers\n",
    "\n",
    "### Context\n",
    "From researching a new topic, to extracting key points from an investor report, or even standardising text documents for input into another LM, the summarisation of text documents has wide ranging and far reaching appications. In the following notebook,  the Transformer Architecture is leveraged to summarise text documents, ranging from various blog posts, to the famous paper, 'Attention is All You Need'. \n",
    "\n",
    "\n",
    "### Solution\n",
    "As mentioned above, the Transformer Architecture is leveraged in order to create a NLP model capable of text summarisation. In particular, a pre-trained Transformer from Hugging Face is used, leveraging its 'Summarization Pipeline' capability. \n",
    "\n",
    "In the case of blog posts, or other similar internet media, Beautiful Soup can be used to scrape the relevant data. In the case of research papers, which are often PDF files, the papers must be saved locally. They are then read in using PdfReader. \n",
    "\n",
    "This scraped data is then preocessed and chunked into blocks of sentences before it is passed to our summariser. Lastly, we export the summarised text so we can use it as desired. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3890b1d",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e37bd",
   "metadata": {},
   "source": [
    "To run the following Jupyter Notebook, the following setup is recommended, although alternatives methods are available. \n",
    "\n",
    "* First create and activate a virtual environment in the desired directory. \n",
    "<br>\n",
    "* Next install the required packages within the virtual environment. \n",
    "\n",
    "*(See the ReadMe.md file for detailed instructions on how the above steps are done)*\n",
    "\n",
    "* Then execute `jupyter notebook` in your terminal, with the virtual environment still activated, in order to open a Jupyter Notebook, whose kernel is the virtual environment created. This ensures we do not need to install all package requirements from the Notebook itself.\n",
    "<br>\n",
    "* The Notebook should then open. If it does not open, check your terminal, as a link to open the Notebook may have been logged here. Once opened, ensure the kernel selected is your virtual environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069c143",
   "metadata": {},
   "source": [
    "In case, you wish to install packages directly from the Jupyter Notebook, uncomment and run the following installations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "# !pip install transformers\n",
    "# !pip install beautifulsoup4\n",
    "#!pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d09d78",
   "metadata": {},
   "source": [
    "Check the imports below exist within the available poackages for the Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea2d929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\r\n",
      "---------------------------- ----------\r\n",
      "absl-py                      1.4.0\r\n",
      "anyio                        3.6.2\r\n",
      "argon2-cffi                  21.3.0\r\n",
      "argon2-cffi-bindings         21.2.0\r\n",
      "arrow                        1.2.3\r\n",
      "asttokens                    2.2.1\r\n",
      "astunparse                   1.6.3\r\n",
      "attrs                        23.1.0\r\n",
      "backcall                     0.2.0\r\n",
      "beautifulsoup4               4.12.2\r\n",
      "bleach                       6.0.0\r\n",
      "cachetools                   5.3.0\r\n",
      "certifi                      2022.12.7\r\n",
      "cffi                         1.15.1\r\n",
      "charset-normalizer           3.1.0\r\n",
      "comm                         0.1.3\r\n",
      "debugpy                      1.6.7\r\n",
      "decorator                    5.1.1\r\n",
      "defusedxml                   0.7.1\r\n",
      "executing                    1.2.0\r\n",
      "fastjsonschema               2.16.3\r\n",
      "filelock                     3.12.0\r\n",
      "flatbuffers                  23.3.3\r\n",
      "fqdn                         1.5.1\r\n",
      "fsspec                       2023.4.0\r\n",
      "gast                         0.4.0\r\n",
      "google-auth                  2.17.3\r\n",
      "google-auth-oauthlib         1.0.0\r\n",
      "google-pasta                 0.2.0\r\n",
      "grpcio                       1.54.0\r\n",
      "h5py                         3.8.0\r\n",
      "huggingface-hub              0.14.1\r\n",
      "idna                         3.4\r\n",
      "importlib-metadata           6.6.0\r\n",
      "importlib-resources          5.12.0\r\n",
      "ipykernel                    6.22.0\r\n",
      "ipython                      8.12.1\r\n",
      "ipython-genutils             0.2.0\r\n",
      "ipywidgets                   8.0.6\r\n",
      "isoduration                  20.11.0\r\n",
      "jax                          0.4.8\r\n",
      "jedi                         0.18.2\r\n",
      "Jinja2                       3.1.2\r\n",
      "jsonpointer                  2.3\r\n",
      "jsonschema                   4.17.3\r\n",
      "jupyter                      1.0.0\r\n",
      "jupyter_client               8.2.0\r\n",
      "jupyter-console              6.6.3\r\n",
      "jupyter_core                 5.3.0\r\n",
      "jupyter-events               0.6.3\r\n",
      "jupyter_server               2.5.0\r\n",
      "jupyter_server_terminals     0.4.4\r\n",
      "jupyterlab-pygments          0.2.2\r\n",
      "jupyterlab-widgets           3.0.7\r\n",
      "keras                        2.12.0\r\n",
      "libclang                     16.0.0\r\n",
      "Markdown                     3.4.3\r\n",
      "MarkupSafe                   2.1.2\r\n",
      "matplotlib-inline            0.1.6\r\n",
      "mistune                      2.0.5\r\n",
      "ml-dtypes                    0.1.0\r\n",
      "mpmath                       1.2.1\r\n",
      "nbclassic                    0.5.6\r\n",
      "nbclient                     0.7.4\r\n",
      "nbconvert                    7.3.1\r\n",
      "nbformat                     5.8.0\r\n",
      "nest-asyncio                 1.5.6\r\n",
      "networkx                     3.0\r\n",
      "notebook                     6.5.4\r\n",
      "notebook_shim                0.2.3\r\n",
      "numpy                        1.23.5\r\n",
      "oauthlib                     3.2.2\r\n",
      "opt-einsum                   3.3.0\r\n",
      "packaging                    23.1\r\n",
      "pandocfilters                1.5.0\r\n",
      "parso                        0.8.3\r\n",
      "pexpect                      4.8.0\r\n",
      "pickleshare                  0.7.5\r\n",
      "Pillow                       9.3.0\r\n",
      "pip                          23.1.2\r\n",
      "pkgutil_resolve_name         1.3.10\r\n",
      "platformdirs                 3.5.0\r\n",
      "prometheus-client            0.16.0\r\n",
      "prompt-toolkit               3.0.38\r\n",
      "protobuf                     4.22.3\r\n",
      "psutil                       5.9.5\r\n",
      "ptyprocess                   0.7.0\r\n",
      "pure-eval                    0.2.2\r\n",
      "pyasn1                       0.5.0\r\n",
      "pyasn1-modules               0.3.0\r\n",
      "pycparser                    2.21\r\n",
      "Pygments                     2.15.1\r\n",
      "pypdf                        3.8.1\r\n",
      "pyrsistent                   0.19.3\r\n",
      "python-dateutil              2.8.2\r\n",
      "python-json-logger           2.0.7\r\n",
      "PyYAML                       6.0\r\n",
      "pyzmq                        25.0.2\r\n",
      "qtconsole                    5.4.2\r\n",
      "QtPy                         2.3.1\r\n",
      "regex                        2023.3.23\r\n",
      "requests                     2.29.0\r\n",
      "requests-oauthlib            1.3.1\r\n",
      "rfc3339-validator            0.1.4\r\n",
      "rfc3986-validator            0.1.1\r\n",
      "rsa                          4.9\r\n",
      "scipy                        1.10.1\r\n",
      "Send2Trash                   1.8.2\r\n",
      "setuptools                   65.6.3\r\n",
      "six                          1.16.0\r\n",
      "sniffio                      1.3.0\r\n",
      "soupsieve                    2.4.1\r\n",
      "stack-data                   0.6.2\r\n",
      "sympy                        1.11.1\r\n",
      "tensorboard                  2.12.2\r\n",
      "tensorboard-data-server      0.7.0\r\n",
      "tensorboard-plugin-wit       1.8.1\r\n",
      "tensorflow                   2.12.0\r\n",
      "tensorflow-estimator         2.12.0\r\n",
      "tensorflow-io-gcs-filesystem 0.32.0\r\n",
      "termcolor                    2.3.0\r\n",
      "terminado                    0.17.1\r\n",
      "tinycss2                     1.2.1\r\n",
      "tokenizers                   0.13.3\r\n",
      "torch                        2.0.0+cpu\r\n",
      "torchaudio                   2.0.1+cpu\r\n",
      "torchvision                  0.15.1+cpu\r\n",
      "tornado                      6.3.1\r\n",
      "tqdm                         4.65.0\r\n",
      "traitlets                    5.9.0\r\n",
      "transformers                 4.28.1\r\n",
      "typing_extensions            4.5.0\r\n",
      "uri-template                 1.2.0\r\n",
      "urllib3                      1.26.15\r\n",
      "wcwidth                      0.2.6\r\n",
      "webcolors                    1.13\r\n",
      "webencodings                 0.5.1\r\n",
      "websocket-client             1.5.1\r\n",
      "Werkzeug                     2.3.2\r\n",
      "wheel                        0.38.4\r\n",
      "widgetsnbextension           4.0.7\r\n",
      "wrapt                        1.14.1\r\n",
      "zipp                         3.15.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd5df8",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ee264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 15:05:30.624194: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-01 15:05:31.350766: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-01 15:05:31.362496: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 15:05:44.818925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline  # Lets us import summarization model\n",
    "from bs4 import BeautifulSoup  # Needed for scraping of text documents\n",
    "import requests  # Needed to make https requests \n",
    "from pypdf import PdfReader  # Needed to read PDF files\n",
    "import tensorflow as tf  # Install preferred ML framework\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b63a50",
   "metadata": {},
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e10764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_url(url: str, tags: list) -> str:\n",
    "    \"\"\"\n",
    "    Returns text from the url specified, where text is retrieved from tags (of the html) specified.\n",
    "    \"\"\"\n",
    "    request = requests.get(url)\n",
    "    if request.ok:\n",
    "        print('URL request successful!')\n",
    "    else:\n",
    "        raise ValueError('URL request unsuccessful!')\n",
    "        \n",
    "    # Extract all tags\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "    results = soup.find_all(tags)\n",
    "    text_list = [result.text for result in results]\n",
    "    text = ' '.join(text_list)\n",
    "    return text\n",
    "\n",
    "def chunk_text(text: str, max_chunk: int = 500) -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of chunks, ready to to be passed to the transformers pipeline. \n",
    "    \"\"\"\n",
    "    # Split text into sentences\n",
    "    eos_punctuation = ['.', '?', '!']\n",
    "    for symbol in eos_punctuation:\n",
    "        text = text.replace(symbol, f'{symbol}<EOS>')\n",
    "    sentences = text.split('<EOS>')\n",
    "    \n",
    "    # Chunk sentences\n",
    "    current_chunk = 0 \n",
    "    chunks = []\n",
    "    for s in sentences:\n",
    "        if len(chunks) == current_chunk + 1: \n",
    "            if len(chunks[current_chunk]) + len(s.split(' ')) <= max_chunk:\n",
    "                chunks[current_chunk].extend(s.split(' '))\n",
    "            else:\n",
    "                current_chunk += 1\n",
    "                chunks.append(s.split(' '))\n",
    "        else:\n",
    "            chunks.append(s.split(' '))\n",
    "\n",
    "    for chunk_id in range(len(chunks)):\n",
    "        chunks[chunk_id] = ' '.join(chunks[chunk_id])\n",
    "        \n",
    "    print(f'Total Chunks: {len(chunks)}')\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def extract_text_from_pdf(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns text from the specified PDF file. \n",
    "    \"\"\"\n",
    "    reader = PdfReader(filename)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \" \"\n",
    "    if len(text) > 0:\n",
    "        print('PDF reading successful!')\n",
    "    return text\n",
    "\n",
    "def extract_text_between_keywords(text: str, start_keyword: str, end_keyword: str):\n",
    "    \"\"\"\n",
    "    Returns text between the start_keyword (Inclusive) and the end_keyword (Not Inclusive). \n",
    "    \"\"\"\n",
    "    start_index = text.find(start_keyword)\n",
    "    end_index = text.find(end_keyword)\n",
    "    \n",
    "    if start_index == -1 or end_index == -1:\n",
    "        return \"\"\n",
    "    \n",
    "    return text[start_index:end_index]\n",
    "\n",
    "def process_text_from_pdf(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the text processed as desired. \n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Only needed for the PDF file. \n",
    "    \n",
    "    #TODO: Abstract and add more processing steps. \n",
    "    \"\"\"\n",
    "    text = extract_text_between_keywords(text, \"Abstract\", \"Acknowledgements\")\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f22271",
   "metadata": {},
   "source": [
    "## 3. Notebook Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a2835d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_FRAMEWORK = 'TORCH'\n",
    "SUMMARY_MAX_LENGTH = 80\n",
    "SUMMARY_MIN_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f596e9f2",
   "metadata": {},
   "source": [
    "## 4. Load Summarization Pipeline\n",
    "\n",
    "*Notes:*\n",
    "- *`pipeline` defaults to use pytorch framework if both pytorch and tensorflow installed.*\n",
    "- *The `pipeline` will load in if not done so before.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa81fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a39f36282348cd86979aa502c35e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d13939854b4f93b384b92d0b4a153f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1673e1cd00ad447db413d7b4a7b3ab7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3c5b1948d54514876b356649310210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f78b268dcd54fd09f40e72ecd8dde5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if ML_FRAMEWORK == 'TORCH':\n",
    "    # Use bart in pytorch\n",
    "    summarizer = pipeline('summarization')\n",
    "elif ML_FRAMEWORK == 'TENSORFLOW':\n",
    "    # Use t5 in tensorflow\n",
    "    summarizer = pipeline('summarization', model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n",
    "else:\n",
    "    raise ValueError('Invalid ML Framework Specified!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f7697",
   "metadata": {},
   "source": [
    "## 6.A Summarise Blog Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a2be9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL request successful\n",
      "Total Chunks: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' In machine learning, regularization, or model complexity control, is an essential and common practice to ensure that a model attains high out-of-sample performance . We can do this by placing a prior on our distribution of models . We will focus on analytical regularization techniques, since their Bayesian interpretation is more well-defined .  We will analyze these claims for regression problems, but they extend to other supervised learning tasks, such as classification, as well . We will focus on rigorously presenting the mathematics behind these claims . In the next section, we will use Bayes’ Rule to derive our L2 regularized estimator .  Using Bayes’ Rule, we can show that the mean and mode of the posterior distribution of w is the solution for LASSO regression when we invoke a Gaussian prior distribution on w . We’ll now examine a similar case with a Laplace prior . Here is the corresponding derivation for Lasso: (Note that in the last step, we set p =  A huge thank you to CODECOGS for their online equation rendering tool! It’s very helpful and easy to use if you want to render mathematics in your Medium articles .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://towardsdatascience.com/a-bayesian-take-on-model-regularization-9356116b6457\"\n",
    "text = extract_text_from_url(URL, ['h1', 'p'])\n",
    "chunks = chunk_text(text)\n",
    "chunk_summaries = summarizer(chunks, max_length=SUMMARY_MAX_LENGTH, min_length=SUMMARY_MIN_LENGTH, do_sample=False)\n",
    "summary = ' '.join([chunk_summary['summary_text'] for chunk_summary in chunk_summaries])\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b536e62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "URL request unsuccessful!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://asianabsolute.co.uk/blog/2021/01/28/what-is-bleu-score/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mURL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m chunks \u001b[38;5;241m=\u001b[39m chunk_text(text)\n\u001b[1;32m      4\u001b[0m chunk_summaries \u001b[38;5;241m=\u001b[39m summarizer(chunks, max_length\u001b[38;5;241m=\u001b[39mSUMMARY_MAX_LENGTH, min_length\u001b[38;5;241m=\u001b[39mSUMMARY_MIN_LENGTH, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m, in \u001b[0;36mextract_text_from_url\u001b[0;34m(url, tags)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL request successful\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL request unsuccessful!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Extract all tags\u001b[39;00m\n\u001b[1;32m     12\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(request\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: URL request unsuccessful!"
     ]
    }
   ],
   "source": [
    "URL = \"https://asianabsolute.co.uk/blog/2021/01/28/what-is-bleu-score/\"\n",
    "text = extract_text_from_url(URL, ['h1', 'p'])\n",
    "chunks = chunk_text(text)\n",
    "chunk_summaries = summarizer(chunks, max_length=SUMMARY_MAX_LENGTH, min_length=SUMMARY_MIN_LENGTH, do_sample=False)\n",
    "summary = ' '.join([chunk_summary['summary_text'] for chunk_summary in chunk_summaries])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8eb0b1",
   "metadata": {},
   "source": [
    "## 6.B Summarise PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40259985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions . Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train .  The Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs .  The Transformer is the ﬁrst transduction model relying solely on self-attention to compute representations of its input and output without using sequence-aligned RNNs or convolution . The model is auto-regressive[10], consuming the previously generated symbols as additional input when generating the next .  An attention function can be described as mapping a query and a set of key-value pairs to an output . The weight assigned to each value is computed by a compatibility function of the query with the corresponding key . We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2) Multi-Head Attention consists of several layers running in parallel .  Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions . With a single attention head, averaging inhibits this with a single head . We employ h= 8 parallel attention layers, or heads, for each of these heads .  The dimensionsality of input and output is dmodel = 512 and the inner-layer has dimensionality of 2048 . In order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the model . Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations for different layer types .  A self-attention layer connects all positions with a constant number of sequentially-executed operations, whereas a recurrent layer requires O(n)sequential operations . The shorter these paths between any combination of positions in the input-and-output sequences, the easier it is to learn long-range dependencies in the network .  This section describes the training regime for our models . We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million sentences . Sentences were encoded using byte-pair encoding [ 3], which has a shared source-target vocabulary of about 37000 tokens . For English-French, we used the signiﬁcantly larger WMT2014 English  The Transformer achieves better BLEU scores than previous state-of-the-art models on the English-to-German and French newstest tests at a fraction of the training cost . The big transformer model (Transformer (big)) outperforms the best previously reported models (including ensembles) by more than 2:0 .  We used beam search as described in the previous section, but no checkpoint averaging . We used values of 2. 8, 3. 7, 7, 6. 0 and 9. 5 TFLOPS for K80, K40, M40 and P100 . All metrics are on the English-to-German translation development set, newstest 2013 .  We trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the Penn Treebank [ 25] We also trained it in a semi-supervised setting, using a vocabulary of 16K tokens for the WSJ only setting and 32K . We performed only a small number of experiments to select the dropout, both attention and residual  The Transformer can be trained signiﬁcantly faster than architectures based on recurrent or convolutional layers . We are excited about the future of attention-based models and plan to apply them to other tasks .  The study is presented at the International Conference on Learning Representations (ICLR) in 2017 . It is the first of its kind in the field of language-language-parsing .  A deep reinforced model for abstractive.ive.summarization.  A deep. reinforced model.  Using the output embedding to improve language models.  The journal of Machine.Machine.Learning Research .  Attentions here shown only for the word ‘making’ are sharp for this word . Figure 3: An example of the attention mechanism following long-distance dependencies in layer 5 of 6 . Figure 4: Two attention heads, apparently involved in anaphora resolution, are shown in Figure 4 . Figure 5: Many attention heads exhibit behaviour that seems related to the structure of the'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "pdf_filepath = os.path.join(current_directory, '../../Resources/attention-is-all-you-need.pdf')\n",
    "\n",
    "text = extract_text_from_pdf(pdf_filepath)\n",
    "processed_text = process_text_from_pdf(text)\n",
    "chunks = chunk_text(text, max_chunk = 400)\n",
    "chunk_summaries = summarizer(chunks, max_length=SUMMARY_MAX_LENGTH, min_length=SUMMARY_MIN_LENGTH, do_sample=False)\n",
    "summary = ' '.join([chunk_summary['summary_text'] for chunk_summary in chunk_summaries])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0f0e8",
   "metadata": {},
   "source": [
    "### Summarising the summarisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8395b5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The Transformer is the ﬁrst transduction model relying solely on self-attention to compute representations of its input and output without using sequence-aligned RNNs or convolution . Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train . The model is  The Transformer achieves better BLEU scores than previous state-of-the-art models on the English-to-German and French newstest tests at a fraction of the training cost . Sentences were encoded using byte-pair encoding [ 3], which has a shared source-target vocabulary of about 37000 tokens . For English-French, we used the signi�'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = chunk_text(summary, max_chunk = 400)\n",
    "chunk_summaries = summarizer(chunks, max_length=SUMMARY_MAX_LENGTH, min_length=SUMMARY_MIN_LENGTH, do_sample=False)\n",
    "summary = ' '.join([chunk_summary['summary_text'] for chunk_summary in chunk_summaries])\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b5cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
